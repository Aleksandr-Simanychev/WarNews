{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01da1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import pymorphy2\n",
    "import nltk\n",
    "import string\n",
    "from datetime import date\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ac1694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrsimanychev/Untitled Folder/RU_JSON\n"
     ]
    }
   ],
   "source": [
    "cd RU_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39644f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir() if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9af7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df = pd.DataFrame({'Channel': [1], 'Post': [1], 'Date': [1], 'Time': [1], 'Location': [1], 'Person': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b727da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for file in onlyfiles:\n",
    "    with open(file, \"r\") as read_file:\n",
    "        datas = json.load(read_file)\n",
    "        for data in datas:\n",
    "            ru_df.loc[counter, 'Channel'] = file[:-5]\n",
    "            try:\n",
    "                ru_df.loc[counter, 'Post'] = data['message']\n",
    "            except:\n",
    "                ru_df.loc[counter, 'Post'] = ''\n",
    "            ru_df.loc[counter, 'Date'] = data['date'][:10]\n",
    "            ru_df.loc[counter, 'Time'] = data['date'][11:19]\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde92142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, NewsNERTagger, PER, NamesExtractor, Doc)\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d35a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ru_df['Post'].size):\n",
    "    LocList = []\n",
    "    doc = Doc(ru_df.loc[i, 'Post'])\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    doc.parse_syntax(syntax_parser)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for span in doc.spans:\n",
    "        span.normalize(morph_vocab)\n",
    "        if span.type == 'LOC':\n",
    "            LocList.append(span.normal)\n",
    "    ru_df.loc[i, 'Location'] = str(LocList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e81a60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df['Location'] = ru_df['Location'].apply(lambda x : re.sub(r\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df['Location'] = ru_df['Location'].apply(lambda x : re.sub(r\"\\[\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df['Location'] = ru_df['Location'].apply(lambda x : re.sub(r\"\\]\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581e513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2831181",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_df=pd.DataFrame({'Region' : [], 'Ukrainian Name':[], 'Russian Name':[], 'Longitude_WGS84':[],\n",
    "       'Latitude_WGS84':[], 'Freq':[], 'Date':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83743491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrsimanychev/Untitled Folder/RU_JSON\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393aa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "RuUaLocDF = pd.read_csv('GeoFile.csv', sep =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1dbb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in ru_df['Date'].unique():\n",
    "    x_day = ', '.join(e for e in ru_df[ru_df['Date'] == date]['Location'].array)\n",
    "    Counter(x_day.split(', ')).most_common()\n",
    "    x_day_df = RuUaLocDF.copy(deep=True)\n",
    "    for place in Counter(x_day.split(', ')).most_common():\n",
    "        if place[0] in list(x_day_df['Russian Name']):\n",
    "            x_day_df.loc[x_day_df[x_day_df['Russian Name'] == place[0]].index, 'Freq'] = place[1]\n",
    "    x_day_df['Date'] = date\n",
    "    x_day_df = x_day_df.dropna()\n",
    "    all_days_df = pd.concat([all_days_df, x_day_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99e50d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_df.to_csv('all_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb8e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrsimanychev/Untitled Folder/UA_JSON\n"
     ]
    }
   ],
   "source": [
    "cd UA_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb30e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles_ua = [f for f in listdir() if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e97773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_df = pd.DataFrame({'Channel': [1], 'Post': [1], 'Date': [1], 'Time': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446416fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for file in onlyfiles_ua:\n",
    "    with open(file, \"r\") as read_file:\n",
    "        datas = json.load(read_file)\n",
    "        for data in datas:\n",
    "            ua_df.loc[counter, 'Channel'] = file[:-5]\n",
    "            try:\n",
    "                ua_df.loc[counter, 'Post'] = data['message']\n",
    "            except:\n",
    "                ua_df.loc[counter, 'Post'] = ''\n",
    "            ua_df.loc[counter, 'Date'] = data['date'][:10]\n",
    "            ua_df.loc[counter, 'Time'] = data['date'][11:19]\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50ea0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ua_df['Post'].size):\n",
    "    LocList = []\n",
    "    doc = Doc(ua_df.loc[i, 'Post'])\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    doc.parse_syntax(syntax_parser)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for span in doc.spans:\n",
    "        span.normalize(morph_vocab)\n",
    "        if span.type == 'LOC':\n",
    "            LocList.append(span.normal)\n",
    "    ua_df.loc[i, 'Location'] = str(LocList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc2094f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_df['Location'] = ua_df['Location'].apply(lambda x : re.sub(r\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b179112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_df['Location'] = ua_df['Location'].apply(lambda x : re.sub(r\"\\[\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6179c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_df['Location'] = ua_df['Location'].apply(lambda x : re.sub(r\"\\]\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fa3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_df_ua=pd.DataFrame({'Region' : [], 'Ukrainian Name':[], 'Russian Name':[], 'Longitude_WGS84':[],\n",
    "       'Latitude_WGS84':[], 'Freq':[], 'Date':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ed4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in ua_df['Date'].unique():\n",
    "    x_day = ', '.join(e for e in ua_df[ua_df['Date'] == date]['Location'].array)\n",
    "    Counter(x_day.split(', ')).most_common()\n",
    "    x_day_df = RuUaLocDF.copy(deep=True)\n",
    "    for place in Counter(x_day.split(', ')).most_common():\n",
    "        if place[0] in list(x_day_df['Russian Name']):\n",
    "            x_day_df.loc[x_day_df[x_day_df['Russian Name'] == place[0]].index, 'Freq'] = place[1]\n",
    "    x_day_df['Date'] = date\n",
    "    x_day_df = x_day_df.dropna()\n",
    "    all_days_df_ua = pd.concat([all_days_df_ua, x_day_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "898adcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_df_ua.to_csv('all_days_ua.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
